name: Container Build & Security

on:
  push:
    paths:
      - 'ocr_service/**'
      - '.github/workflows/**'
  workflow_dispatch:
  schedule:
    - cron: '0 6 * * *' # Daily at 06:00 UTC (scheduled Lambda benchmarking)


permissions:
  contents: read

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  build-and-scan:
    runs-on: ubuntu-latest
    env:
      FAIL_ON_SCAN: 'false' # set to 'true' to make Trivy/Dockle failures block the job
    steps:
      - name: Checkout
        uses: actions/checkout@v4


      - name: Build Docker image
        id: build_image
        run: |
          IMAGE=al-ocr-service:ci
          for i in 1 2 3; do
            if docker build -t "$IMAGE" -f ocr_service/Dockerfile .; then
              break
            fi
            if [ $i -lt 3 ]; then
              echo "Build failed; retrying in $((i*10))s..."
              sleep $((i*10))
            else
              echo "Docker build failed after $i attempts."
              exit 1
            fi
          done
          echo "image=$IMAGE" >> $GITHUB_OUTPUT

      - name: Trivy Scan (table output)
        run: |
          set -euxo pipefail
          IMAGE=${{ steps.build_image.outputs.image }}
          # Mount the repo into the Trivy container so table output can access local images and any files are written to the runner
          docker run --rm -v /var/run/docker.sock:/var/run/docker.sock -v "${PWD}:/workdir" -w /workdir aquasec/trivy image -f table "$IMAGE" || true
      - name: Trivy Scan (JSON output)
        run: |
          set -euxo pipefail
          IMAGE=${{ steps.build_image.outputs.image }}
          # Write JSON results to the mounted workspace so the file is available to subsequent steps
          docker run --rm -v /var/run/docker.sock:/var/run/docker.sock -v "${PWD}:/workdir" -w /workdir aquasec/trivy image -f json -o trivy-results.json "$IMAGE" || true

      - name: "Optional: Fail on Trivy HIGH/CRITICAL (enable via FAIL_ON_SCAN=true)"
        if: env.FAIL_ON_SCAN == 'true'
        run: |
          set -euo pipefail
          if [ -f trivy-results.json ]; then
            HIGH=$(jq '[.Results[].Vulnerabilities[]? | select(.Severity=="HIGH" or .Severity=="CRITICAL")] | length' trivy-results.json)
            if [ "$HIGH" -gt 0 ]; then
              echo "Found $HIGH high/critical vulnerabilities in trivy-results.json"
              exit 1
            fi
          else
            echo "trivy-results.json not found"
            exit 1
          fi

      - name: Install Dockle
        run: |
          set -euxo pipefail
          DOCKLE_VERSION="0.4.9"
          curl -fsSL "https://github.com/goodwithtech/dockle/releases/download/v${DOCKLE_VERSION}/dockle_${DOCKLE_VERSION}_Linux-64bit.tar.gz" -o dockle.tar.gz
          tar -xzf dockle.tar.gz
          sudo mv dockle /usr/local/bin/dockle

      - name: Run Dockle (CIS checks - JSON)
        run: |
          set -euxo pipefail
          dockle -f json -o dockle-results.json ${{ steps.build_image.outputs.image }} || true

      - name: "Optional: Fail on Dockle findings (enable via FAIL_ON_SCAN=true)"
        if: env.FAIL_ON_SCAN == 'true'
        run: |
          set -euo pipefail
          if [ -f dockle-results.json ]; then
            # Dockle outputs an array of findings; fail if any findings present
            COUNT=$(jq 'length' dockle-results.json || echo 0)
            if [ "$COUNT" -gt 0 ]; then
              echo "Dockle reported $COUNT findings"
              exit 1
            fi
          else
            echo "dockle-results.json not found"
            exit 1
          fi

      - name: Run container runtime checks
        run: |
          bash tests/container/run_container_checks.sh ${{ steps.build_image.outputs.image }} 8080

      - name: Upload scan artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: container-scans
          path: |
            trivy-results.json
            dockle-results.json
            container-logs.txt

  lint-dockerfile:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Install hadolint
        run: |
          sudo wget -O /usr/local/bin/hadolint https://github.com/hadolint/hadolint/releases/latest/download/hadolint-$(uname -s)-$(uname -m) && sudo chmod +x /usr/local/bin/hadolint
      - name: Lint Dockerfile
        run: |
          set -euo pipefail
          # Run hadolint but don't fail the workflow on warnings â€” treat lint as advisory
          hadolint ocr_service/Dockerfile || true
  lambda-benchmark:
    name: Lambda Cold-Start & Synthetic Benchmark
    runs-on: ubuntu-latest
    needs: build-and-scan
    env:
      AWS_REGION: ${{ secrets.AWS_REGION }}
      AWS_ACCOUNT_ID: ${{ secrets.AWS_ACCOUNT_ID }}
      ECR_REPOSITORY: ${{ secrets.ECR_REPOSITORY }}
      LAMBDA_FUNCTION_NAME: ${{ secrets.AWS_LAMBDA_FUNCTION_NAME }}
      LAMBDA_ROLE_ARN: ${{ secrets.AWS_LAMBDA_ROLE_ARN }}
      ENABLE_LAMBDA_ROLLBACK: ${{ secrets.ENABLE_LAMBDA_ROLLBACK }}
      SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Validate required secrets
        run: |
          missing=""
          for var in AWS_REGION AWS_ACCOUNT_ID ECR_REPOSITORY LAMBDA_FUNCTION_NAME AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY; do
            if [ -z "${!var:-}" ]; then
              missing="$missing $var"
            fi
          done
          if [ -n "$missing" ]; then
            echo "Skipping Lambda benchmark: missing required secrets:$missing"
            exit 0
          fi

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to ECR
        run: |
          aws ecr get-login-password --region "$AWS_REGION" | docker login --username AWS --password-stdin "$AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com"

      - name: Ensure ECR repository exists
        run: |
          if ! aws ecr describe-repositories --repository-names "$ECR_REPOSITORY" >/dev/null 2>&1; then
            aws ecr create-repository --repository-name "$ECR_REPOSITORY" || true
          fi

      - name: Tag and push image to ECR
        run: |
          IMAGE_TAG="$AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/$ECR_REPOSITORY:ci-${{ github.run_id }}"
          docker tag al-ocr-service:ci "$IMAGE_TAG"
          docker push "$IMAGE_TAG"
          echo "IMAGE_TAG=$IMAGE_TAG" >> $GITHUB_ENV

      - name: Capture previous Lambda image (if exists)
        id: prev_image
        run: |
          FN="$LAMBDA_FUNCTION_NAME"
          PREV_IMAGE=$(aws lambda get-function --function-name "$FN" --query 'Configuration.Code' --output text 2>/dev/null || true)
          # Attempt to extract ImageUri if present
          PREV_IMAGE_URI=$(aws lambda get-function --function-name "$FN" --query 'Code.ImageUri' --output text 2>/dev/null || true || true)
          echo "PREV_IMAGE_URI=${PREV_IMAGE_URI:-}" >> $GITHUB_ENV
          echo "Previous image: ${PREV_IMAGE_URI:-<none>}"

      - name: Deploy or update Lambda image
        run: |
          set -euo pipefail
          FN="$LAMBDA_FUNCTION_NAME"
          IMAGE_URI="$IMAGE_TAG"
          if aws lambda get-function --function-name "$FN" >/dev/null 2>&1; then
            echo "Updating Lambda function code to image $IMAGE_URI"
            aws lambda update-function-code --function-name "$FN" --image-uri "$IMAGE_URI" --publish
          else
            if [ -z "${LAMBDA_ROLE_ARN:-}" ]; then
              echo "LAMBDA_ROLE_ARN not provided. Cannot create Lambda function. Exiting." >&2
              exit 2
            fi
            echo "Creating Lambda function $FN with image $IMAGE_URI"
            aws lambda create-function --function-name "$FN" --package-type Image --code ImageUri="$IMAGE_URI" --role "$LAMBDA_ROLE_ARN" --timeout 30 --memory-size 1024 --publish
          fi

      - name: Wait for Lambda deployment
        run: |
          sleep 10

      - name: Run cold-start and benchmark invocations
        id: benchmark
        run: |
          FN="$LAMBDA_FUNCTION_NAME"
          OUT_FILE=./lambda_benchmark_results.txt
          echo "Lambda Benchmark Results" > $OUT_FILE

          # force a new instance by updating environment variable to a new value to trigger cold start
          aws lambda update-function-configuration --function-name "$FN" --environment "Variables={CI_RUN_ID=${{ github.run_id }}}" || true
          sleep 5

          # first invocation (cold start)
          START=$(date +%s%3N)
          aws lambda invoke --function-name "$FN" --payload '{}' response.json >/dev/null
          END=$(date +%s%3N)
          COLD_MS=$((END-START))
          echo "cold_start_ms: $COLD_MS" | tee -a $OUT_FILE

          # warm invocations
          ITER=5
          for i in $(seq 1 $ITER); do
            START=$(date +%s%3N)
            aws lambda invoke --function-name "$FN" --payload '{}' response.json >/dev/null
            END=$(date +%s%3N)
            ELAPSED=$((END-START))
            echo "warm_invocation_$i: $ELAPSED" | tee -a $OUT_FILE
            sleep 0.5
          done

          # compute summary and expose output via GITHUB_OUTPUT
          WARM_MEAN=$(awk '/warm_invocation_/ {sum+= $2; count+=1} END {print (count?sum/count:0)}' $OUT_FILE || echo 0)
          WARM_MAX=$(awk '/warm_invocation_/ {if($2>max) max=$2} END {print (max?max:0)}' $OUT_FILE || echo 0)
          echo "cold_start_ms=$COLD_MS" | tee -a $OUT_FILE
          echo "warm_mean_ms=$WARM_MEAN" | tee -a $OUT_FILE
          echo "warm_max_ms=$WARM_MAX" | tee -a $OUT_FILE
          echo "result_file=$OUT_FILE" >> $GITHUB_OUTPUT

      - name: Upload benchmark artifact
        uses: actions/upload-artifact@v4
        with:
          name: lambda-benchmark-results
          path: lambda_benchmark_results.txt

      - name: Conditional rollback (optional)
        if: env.ENABLE_LAMBDA_ROLLBACK == 'true' && env.PREV_IMAGE_URI != ''
        run: |
          set -euo pipefail
          THRESHOLD=${{ secrets.ROLLBACK_COLD_MS }}
          if [ -z "${THRESHOLD:-}" ]; then
            echo "ROLLBACK_COLD_MS not set; skipping automatic rollback check."
            exit 0
          fi
          COLD_MS=$(awk -F': ' '/cold_start_ms/ {print $2; exit}' lambda_benchmark_results.txt || echo 0)
          echo "Cold start measured: $COLD_MS ms; threshold: $THRESHOLD ms"
          if [ "$COLD_MS" -gt "$THRESHOLD" ]; then
            echo "Cold start exceeded threshold; rolling back to ${PREV_IMAGE_URI}" >&2
            aws lambda update-function-code --function-name "$LAMBDA_FUNCTION_NAME" --image-uri "${PREV_IMAGE_URI}" --publish
            echo "Rollback performed to ${PREV_IMAGE_URI}"
            echo "rollback_performed=true" >> $GITHUB_OUTPUT
          else
            echo "No rollback necessary." >> $GITHUB_OUTPUT
          fi

      - name: Slack notification (optional)
        if: env.SLACK_WEBHOOK_URL
        run: |
          WEBHOOK=${{ env.SLACK_WEBHOOK_URL }}
          BODY=$(cat lambda_benchmark_results.txt | sed ':a;N;$!ba;s/\n/\n/g')
          PAYLOAD=$(jq -n --arg text "Lambda benchmark run ${{ github.run_id }} for ${{ env.LAMBDA_FUNCTION_NAME }}\n\n$BODY" '{text: $text}')
          curl -sS -X POST -H 'Content-type: application/json' --data "$PAYLOAD" "$WEBHOOK"
